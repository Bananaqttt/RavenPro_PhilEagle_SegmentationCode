{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b2162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing manifest structure...\n",
      "‚úÖ Found existing manifest with 12 columns\n",
      "\n",
      "Loading and filtering metadata...\n",
      "‚úÖ Found 1125 valid noise files.\n",
      "Starting group_id from: 1813\n",
      "\n",
      "üìâ Target to fill: 2969 files\n",
      "üìÇ Copying from: D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/Audio Wise V1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1125/1125 [00:01<00:00, 626.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® Finished! Copied 1125 noise files.\n",
      "\n",
      "Updating master_manifest.csv...\n",
      "‚úÖ Master manifest updated successfully. Added 1125 new rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# ===============================\n",
    "# USER SETTINGS\n",
    "# ===============================\n",
    "NOISE_SOURCE_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/Audio Wise V1.0\"\n",
    "METADATA_PATH = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/Metadata V1.0 FSC22.csv\"\n",
    "EXISTING_OUTPUT_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/3_SegmentedAudios\"\n",
    "\n",
    "TARGET_DEFICIT = 2969\n",
    "\n",
    "ALLOWED_CLASSES = [\n",
    "    'Rain', 'Thunderstorm', 'WaterDrops', 'Wind', 'Silence', \n",
    "    'TreeFalling', 'Whistling', 'Insect', 'Frog', \n",
    "    'BirdChirping', 'WingFlapping', 'Squirrel', 'Footsteps', 'Clapping',\n",
    "    'WolfHowl', 'Speaking'\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# STEP 1: LOAD EXISTING MANIFEST\n",
    "# ===============================\n",
    "manifest_path = os.path.join(EXISTING_OUTPUT_FOLDER, \"master_manifest_NoEagle.csv\")\n",
    "\n",
    "print(\"Loading existing manifest structure...\")\n",
    "\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(\"‚ùå No existing manifest found. Please ensure master_manifest.csv exists.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    existing_manifest = pd.read_csv(manifest_path)\n",
    "    manifest_columns = existing_manifest.columns.tolist()\n",
    "    print(f\"‚úÖ Found existing manifest with {len(manifest_columns)} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading existing manifest: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ===============================\n",
    "# LOAD & FILTER METADATA\n",
    "# ===============================\n",
    "print(\"\\nLoading and filtering metadata...\")\n",
    "try:\n",
    "    meta_df = pd.read_csv(METADATA_PATH)\n",
    "    \n",
    "    # Filter by class\n",
    "    filtered_df = meta_df[meta_df['Class Name'].isin(ALLOWED_CLASSES)].copy()\n",
    "    \n",
    "    # Shuffle to get a random mix\n",
    "    filtered_df = filtered_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(filtered_df)} valid noise files.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading metadata: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ===============================\n",
    "# PREPARE FOR COPYING\n",
    "# ===============================\n",
    "# Calculate next group_id to avoid conflicts\n",
    "if len(existing_manifest) > 0 and 'group_id' in manifest_columns:\n",
    "    try:\n",
    "        next_group_id = int(existing_manifest['group_id'].max()) + 1\n",
    "    except:\n",
    "        next_group_id = 10000\n",
    "else:\n",
    "    next_group_id = 10000\n",
    "\n",
    "print(f\"Starting group_id from: {next_group_id}\")\n",
    "\n",
    "# ===============================\n",
    "# COPY FILES\n",
    "# ===============================\n",
    "created_count = 0\n",
    "segments_data = []\n",
    "\n",
    "print(f\"\\nüìâ Target to fill: {TARGET_DEFICIT} files\")\n",
    "print(f\"üìÇ Copying from: {NOISE_SOURCE_FOLDER}\")\n",
    "\n",
    "# Iterate through the filtered list\n",
    "for index, row in tqdm(filtered_df.iterrows(), total=min(len(filtered_df), TARGET_DEFICIT)):\n",
    "    if created_count >= TARGET_DEFICIT:\n",
    "        break\n",
    "        \n",
    "    original_filename = str(row['Dataset File Name']).strip()\n",
    "    noise_class = str(row['Class Name']).strip()\n",
    "    \n",
    "    source_path = os.path.join(NOISE_SOURCE_FOLDER, original_filename)\n",
    "    \n",
    "    if not os.path.exists(source_path):\n",
    "        continue\n",
    "        \n",
    "    # Prepare Destination\n",
    "    new_filename = f\"GeneralForest_{noise_class}_{original_filename}\"\n",
    "    \n",
    "    location = \"GeneralForest\"\n",
    "    label = \"NoEagleSound\"\n",
    "    \n",
    "    # Save Folder: Output / GeneralForest / NoEagleSound\n",
    "    save_folder = os.path.join(EXISTING_OUTPUT_FOLDER, location, label)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    dest_path = os.path.join(save_folder, new_filename)\n",
    "    \n",
    "    try:\n",
    "        # COPY THE FILE\n",
    "        shutil.copy2(source_path, dest_path)\n",
    "        \n",
    "        # Create a row matching the existing manifest structure\n",
    "        new_row = {}\n",
    "        \n",
    "        # Fill in columns that we have data for\n",
    "        column_mapping = {\n",
    "            'label': label,\n",
    "            'label_base': label,\n",
    "            'label_full': label,\n",
    "            'group_id': next_group_id + created_count,\n",
    "            'location_id': location,\n",
    "            'segment_filename': new_filename,\n",
    "            'output_folder': os.path.join(location, label),\n",
    "            'source_audio': original_filename,\n",
    "            'start': '',\n",
    "            'end': '',\n",
    "            'quality': '',\n",
    "            'selection_numbers': '',\n",
    "        }\n",
    "        \n",
    "        # Initialize all columns from existing manifest structure\n",
    "        for col in manifest_columns:\n",
    "            if col in column_mapping:\n",
    "                new_row[col] = column_mapping[col]\n",
    "            else:\n",
    "                new_row[col] = ''  # Leave blank if no data available\n",
    "        \n",
    "        segments_data.append(new_row)\n",
    "        created_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error copying {original_filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚ú® Finished! Copied {created_count} noise files.\")\n",
    "\n",
    "# ===============================\n",
    "# UPDATE MASTER MANIFEST\n",
    "# ===============================\n",
    "if segments_data:\n",
    "    print(\"\\nUpdating master_manifest.csv...\")\n",
    "    try:\n",
    "        new_df = pd.DataFrame(segments_data)\n",
    "        \n",
    "        # Ensure column order matches existing manifest\n",
    "        new_df = new_df[manifest_columns]\n",
    "        \n",
    "        # Append to existing manifest\n",
    "        combined_df = pd.concat([existing_manifest, new_df], ignore_index=True)\n",
    "        \n",
    "        # Save updated manifest\n",
    "        combined_df.to_csv(manifest_path, index=False)\n",
    "        print(f\"‚úÖ Master manifest updated successfully. Added {created_count} new rows.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating manifest: {e}\")\n",
    "        # Backup save\n",
    "        pd.DataFrame(segments_data).to_csv(\n",
    "            os.path.join(EXISTING_OUTPUT_FOLDER, \"added_noise_manifest_backup.csv\"), \n",
    "            index=False\n",
    "        )\n",
    "        print(\"   Saved new data to 'added_noise_manifest_backup.csv' instead.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No files were copied. Manifest not updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d637270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "‚úÖ Found 1440 unique source files.\n",
      "üìâ Target needed: 2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2229/2229 [00:49<00:00, 44.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® DONE! Created 2229 files (1440 originals + 789 augmented).\n",
      "Updating manifest...\n",
      "‚úÖ Manifest updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# ===============================\n",
    "# USER SETTINGS\n",
    "# ===============================\n",
    "NOISE_SOURCE_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive2/audio/audio\"\n",
    "METADATA_PATH = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive2/esc50.csv\"\n",
    "EXISTING_OUTPUT_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/3_SegmentedAudios\"\n",
    "\n",
    "TARGET_DEFICIT = 2229 \n",
    "\n",
    "ALLOWED_CLASSES = [\n",
    "    'chirping_birds', 'thunderstorm', 'crow', 'door_wood_knock', 'pouring_water', \n",
    "    'clapping', 'church_bells', 'water_drops', 'wind', 'sheep', 'frog', \n",
    "    'fireworks', 'cow', 'crackling_fire', 'hen', 'insects', 'hand_saw', \n",
    "    'pig', 'rooster', 'sea_waves', 'dog', 'breathing', 'siren', 'snoring', \n",
    "    'airplane', 'cat', 'door_wood_creaking', 'crickets', 'coughing', \n",
    "    'chainsaw', 'drinking_sipping', 'laughing', 'glass_breaking', \n",
    "    'engine', 'footsteps', 'crying_baby', 'can_opening'\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# LOAD MANIFESTS\n",
    "# ===============================\n",
    "manifest_path = os.path.join(EXISTING_OUTPUT_FOLDER, \"master_manifest_NoEagle.csv\")\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(\"‚ùå No existing manifest found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "existing_manifest = pd.read_csv(manifest_path)\n",
    "manifest_columns = existing_manifest.columns.tolist()\n",
    "\n",
    "# Determine next group ID\n",
    "if 'group_id' in existing_manifest.columns and not existing_manifest.empty:\n",
    "    next_group_id = int(existing_manifest['group_id'].max()) + 1\n",
    "else:\n",
    "    next_group_id = 10000\n",
    "\n",
    "# ===============================\n",
    "# PREPARE SOURCE LIST\n",
    "# ===============================\n",
    "print(\"Loading metadata...\")\n",
    "meta_df = pd.read_csv(METADATA_PATH)\n",
    "filtered_df = meta_df[meta_df['category'].isin(ALLOWED_CLASSES)].copy()\n",
    "# Shuffle once\n",
    "filtered_df = filtered_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Found {len(filtered_df)} unique source files.\")\n",
    "print(f\"üìâ Target needed: {TARGET_DEFICIT}\")\n",
    "\n",
    "# ===============================\n",
    "# FILL LOOP (COPY -> AUGMENT)\n",
    "# ===============================\n",
    "created_count = 0\n",
    "segments_data = []\n",
    "source_index = 0\n",
    "total_sources = len(filtered_df)\n",
    "\n",
    "pbar = tqdm(total=TARGET_DEFICIT)\n",
    "\n",
    "while created_count < TARGET_DEFICIT:\n",
    "    # Cycle through the list repeatedly if needed\n",
    "    row = filtered_df.iloc[source_index % total_sources]\n",
    "    source_index += 1\n",
    "    \n",
    "    orig_filename = str(row['filename']).strip()\n",
    "    noise_class = str(row['category']).strip()\n",
    "    source_path = os.path.join(NOISE_SOURCE_FOLDER, orig_filename)\n",
    "    \n",
    "    if not os.path.exists(source_path): continue\n",
    "\n",
    "    # Determine: Copy (Round 1) or Augment (Round 2+)?\n",
    "    is_augmentation = (source_index > total_sources)\n",
    "    \n",
    "    # Destination Setup\n",
    "    location = \"GeneralForest\"\n",
    "    label = \"NoEagleSound\"\n",
    "    save_folder = os.path.join(EXISTING_OUTPUT_FOLDER, location, label)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        if not is_augmentation:\n",
    "            # --- METHOD A: DIRECT COPY (Fast) ---\n",
    "            new_filename = f\"GeneralForest_{noise_class}_{orig_filename}\"\n",
    "            dest_path = os.path.join(save_folder, new_filename)\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "            \n",
    "        else:\n",
    "            # --- METHOD B: AUGMENTATION (Fill the rest) ---\n",
    "            # Load\n",
    "            y, sr = librosa.load(source_path, sr=None)\n",
    "            \n",
    "            # Augment: Pitch Shift (Randomly slightly higher or lower)\n",
    "            steps = np.random.uniform(-1.5, 1.5)\n",
    "            y_aug = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
    "            \n",
    "            # Save as new file\n",
    "            new_filename = f\"GeneralForest_{noise_class}_aug{source_index}_{orig_filename}\"\n",
    "            dest_path = os.path.join(save_folder, new_filename)\n",
    "            sf.write(dest_path, y_aug, sr)\n",
    "\n",
    "        # Add to Manifest Data\n",
    "        new_row = {col: '' for col in manifest_columns} # Init empty\n",
    "        new_row.update({\n",
    "            'label': label,\n",
    "            'label_base': label,\n",
    "            'label_full': label,\n",
    "            'group_id': next_group_id + created_count,\n",
    "            'location_id': location,\n",
    "            'segment_filename': new_filename,\n",
    "            'output_folder': os.path.join(location, label),\n",
    "            'source_audio': orig_filename,\n",
    "            'start': 0.0,\n",
    "            'end': 5.0,\n",
    "            'quality': 'N/A',\n",
    "            'selection_numbers': 'None'\n",
    "        })\n",
    "        \n",
    "        segments_data.append(new_row)\n",
    "        created_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        pass\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n‚ú® DONE! Created {created_count} files ({len(filtered_df)} originals + {created_count - len(filtered_df)} augmented).\")\n",
    "\n",
    "# ===============================\n",
    "# SAVE MANIFEST\n",
    "# ===============================\n",
    "if segments_data:\n",
    "    print(\"Updating manifest...\")\n",
    "    new_df = pd.DataFrame(segments_data)\n",
    "    new_df = new_df[manifest_columns] # Align columns\n",
    "    combined = pd.concat([existing_manifest, new_df], ignore_index=True)\n",
    "    combined.to_csv(manifest_path, index=False)\n",
    "    print(\"‚úÖ Manifest updated.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
