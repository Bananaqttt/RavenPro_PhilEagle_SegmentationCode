{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b2162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing manifest structure...\n",
      "‚úÖ Found existing manifest with 12 columns\n",
      "\n",
      "Loading and filtering metadata...\n",
      "‚úÖ Found 1125 valid noise files.\n",
      "Starting group_id from: 1813\n",
      "\n",
      "üìâ Target to fill: 2969 files\n",
      "üìÇ Copying from: D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/Audio Wise V1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1125/1125 [00:01<00:00, 626.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® Finished! Copied 1125 noise files.\n",
      "\n",
      "Updating master_manifest.csv...\n",
      "‚úÖ Master manifest updated successfully. Added 1125 new rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# ===============================\n",
    "# USER SETTINGS\n",
    "# ===============================\n",
    "NOISE_SOURCE_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/Audio Wise V1.0\"\n",
    "METADATA_PATH = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/Metadata V1.0 FSC22.csv\"\n",
    "EXISTING_OUTPUT_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/3_SegmentedAudios\"\n",
    "\n",
    "TARGET_DEFICIT = 2969\n",
    "\n",
    "ALLOWED_CLASSES = [\n",
    "    'Rain', 'Thunderstorm', 'WaterDrops', 'Wind', 'Silence', \n",
    "    'TreeFalling', 'Whistling', 'Insect', 'Frog', \n",
    "    'BirdChirping', 'WingFlapping', 'Squirrel', 'Footsteps', 'Clapping',\n",
    "    'WolfHowl', 'Speaking'\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# STEP 1: LOAD EXISTING MANIFEST\n",
    "# ===============================\n",
    "manifest_path = os.path.join(EXISTING_OUTPUT_FOLDER, \"master_manifest_NoEagle.csv\")\n",
    "\n",
    "print(\"Loading existing manifest structure...\")\n",
    "\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(\"‚ùå No existing manifest found. Please ensure master_manifest.csv exists.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    existing_manifest = pd.read_csv(manifest_path)\n",
    "    manifest_columns = existing_manifest.columns.tolist()\n",
    "    print(f\"‚úÖ Found existing manifest with {len(manifest_columns)} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading existing manifest: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ===============================\n",
    "# LOAD & FILTER METADATA\n",
    "# ===============================\n",
    "print(\"\\nLoading and filtering metadata...\")\n",
    "try:\n",
    "    meta_df = pd.read_csv(METADATA_PATH)\n",
    "    \n",
    "    # Filter by class\n",
    "    filtered_df = meta_df[meta_df['Class Name'].isin(ALLOWED_CLASSES)].copy()\n",
    "    \n",
    "    # Shuffle to get a random mix\n",
    "    filtered_df = filtered_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(filtered_df)} valid noise files.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading metadata: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ===============================\n",
    "# PREPARE FOR COPYING\n",
    "# ===============================\n",
    "# Calculate next group_id to avoid conflicts\n",
    "if len(existing_manifest) > 0 and 'group_id' in manifest_columns:\n",
    "    try:\n",
    "        next_group_id = int(existing_manifest['group_id'].max()) + 1\n",
    "    except:\n",
    "        next_group_id = 10000\n",
    "else:\n",
    "    next_group_id = 10000\n",
    "\n",
    "print(f\"Starting group_id from: {next_group_id}\")\n",
    "\n",
    "# ===============================\n",
    "# COPY FILES\n",
    "# ===============================\n",
    "created_count = 0\n",
    "segments_data = []\n",
    "\n",
    "print(f\"\\nüìâ Target to fill: {TARGET_DEFICIT} files\")\n",
    "print(f\"üìÇ Copying from: {NOISE_SOURCE_FOLDER}\")\n",
    "\n",
    "# Iterate through the filtered list\n",
    "for index, row in tqdm(filtered_df.iterrows(), total=min(len(filtered_df), TARGET_DEFICIT)):\n",
    "    if created_count >= TARGET_DEFICIT:\n",
    "        break\n",
    "        \n",
    "    original_filename = str(row['Dataset File Name']).strip()\n",
    "    noise_class = str(row['Class Name']).strip()\n",
    "    \n",
    "    source_path = os.path.join(NOISE_SOURCE_FOLDER, original_filename)\n",
    "    \n",
    "    if not os.path.exists(source_path):\n",
    "        continue\n",
    "        \n",
    "    # Prepare Destination\n",
    "    new_filename = f\"GeneralForest_{noise_class}_{original_filename}\"\n",
    "    \n",
    "    location = \"GeneralForest\"\n",
    "    label = \"NoEagleSound\"\n",
    "    \n",
    "    # Save Folder: Output / GeneralForest / NoEagleSound\n",
    "    save_folder = os.path.join(EXISTING_OUTPUT_FOLDER, location, label)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    dest_path = os.path.join(save_folder, new_filename)\n",
    "    \n",
    "    try:\n",
    "        # COPY THE FILE\n",
    "        shutil.copy2(source_path, dest_path)\n",
    "        \n",
    "        # Create a row matching the existing manifest structure\n",
    "        new_row = {}\n",
    "        \n",
    "        # Fill in columns that we have data for\n",
    "        column_mapping = {\n",
    "            'label': label,\n",
    "            'label_base': label,\n",
    "            'label_full': label,\n",
    "            'group_id': next_group_id + created_count,\n",
    "            'location_id': location,\n",
    "            'segment_filename': new_filename,\n",
    "            'output_folder': os.path.join(location, label),\n",
    "            'source_audio': original_filename,\n",
    "            'start': '',\n",
    "            'end': '',\n",
    "            'quality': '',\n",
    "            'selection_numbers': '',\n",
    "        }\n",
    "        \n",
    "        # Initialize all columns from existing manifest structure\n",
    "        for col in manifest_columns:\n",
    "            if col in column_mapping:\n",
    "                new_row[col] = column_mapping[col]\n",
    "            else:\n",
    "                new_row[col] = ''  # Leave blank if no data available\n",
    "        \n",
    "        segments_data.append(new_row)\n",
    "        created_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error copying {original_filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n‚ú® Finished! Copied {created_count} noise files.\")\n",
    "\n",
    "# ===============================\n",
    "# UPDATE MASTER MANIFEST\n",
    "# ===============================\n",
    "if segments_data:\n",
    "    print(\"\\nUpdating master_manifest.csv...\")\n",
    "    try:\n",
    "        new_df = pd.DataFrame(segments_data)\n",
    "        \n",
    "        # Ensure column order matches existing manifest\n",
    "        new_df = new_df[manifest_columns]\n",
    "        \n",
    "        # Append to existing manifest\n",
    "        combined_df = pd.concat([existing_manifest, new_df], ignore_index=True)\n",
    "        \n",
    "        # Save updated manifest\n",
    "        combined_df.to_csv(manifest_path, index=False)\n",
    "        print(f\"‚úÖ Master manifest updated successfully. Added {created_count} new rows.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating manifest: {e}\")\n",
    "        # Backup save\n",
    "        pd.DataFrame(segments_data).to_csv(\n",
    "            os.path.join(EXISTING_OUTPUT_FOLDER, \"added_noise_manifest_backup.csv\"), \n",
    "            index=False\n",
    "        )\n",
    "        print(\"   Saved new data to 'added_noise_manifest_backup.csv' instead.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No files were copied. Manifest not updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d637270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "‚úÖ Found 1440 unique source files.\n",
      "üìâ Target needed: 2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2229/2229 [00:49<00:00, 44.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® DONE! Created 2229 files (1440 originals + 789 augmented).\n",
      "Updating manifest...\n",
      "‚úÖ Manifest updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# ===============================\n",
    "# USER SETTINGS\n",
    "# ===============================\n",
    "NOISE_SOURCE_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive2/audio/audio\"\n",
    "METADATA_PATH = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive2/esc50.csv\"\n",
    "EXISTING_OUTPUT_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/3_SegmentedAudios\"\n",
    "\n",
    "TARGET_DEFICIT = 2229 \n",
    "\n",
    "ALLOWED_CLASSES = [\n",
    "    'chirping_birds', 'thunderstorm', 'crow', 'door_wood_knock', 'pouring_water', \n",
    "    'clapping', 'church_bells', 'water_drops', 'wind', 'sheep', 'frog', \n",
    "    'fireworks', 'cow', 'crackling_fire', 'hen', 'insects', 'hand_saw', \n",
    "    'pig', 'rooster', 'sea_waves', 'dog', 'breathing', 'siren', 'snoring', \n",
    "    'airplane', 'cat', 'door_wood_creaking', 'crickets', 'coughing', \n",
    "    'chainsaw', 'drinking_sipping', 'laughing', 'glass_breaking', \n",
    "    'engine', 'footsteps', 'crying_baby', 'can_opening'\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# LOAD MANIFESTS\n",
    "# ===============================\n",
    "manifest_path = os.path.join(EXISTING_OUTPUT_FOLDER, \"master_manifest_NoEagle.csv\")\n",
    "if not os.path.exists(manifest_path):\n",
    "    print(\"‚ùå No existing manifest found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "existing_manifest = pd.read_csv(manifest_path)\n",
    "manifest_columns = existing_manifest.columns.tolist()\n",
    "\n",
    "# Determine next group ID\n",
    "if 'group_id' in existing_manifest.columns and not existing_manifest.empty:\n",
    "    next_group_id = int(existing_manifest['group_id'].max()) + 1\n",
    "else:\n",
    "    next_group_id = 10000\n",
    "\n",
    "# ===============================\n",
    "# PREPARE SOURCE LIST\n",
    "# ===============================\n",
    "print(\"Loading metadata...\")\n",
    "meta_df = pd.read_csv(METADATA_PATH)\n",
    "filtered_df = meta_df[meta_df['category'].isin(ALLOWED_CLASSES)].copy()\n",
    "# Shuffle once\n",
    "filtered_df = filtered_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Found {len(filtered_df)} unique source files.\")\n",
    "print(f\"üìâ Target needed: {TARGET_DEFICIT}\")\n",
    "\n",
    "# ===============================\n",
    "# FILL LOOP (COPY -> AUGMENT)\n",
    "# ===============================\n",
    "created_count = 0\n",
    "segments_data = []\n",
    "source_index = 0\n",
    "total_sources = len(filtered_df)\n",
    "\n",
    "pbar = tqdm(total=TARGET_DEFICIT)\n",
    "\n",
    "while created_count < TARGET_DEFICIT:\n",
    "    # Cycle through the list repeatedly if needed\n",
    "    row = filtered_df.iloc[source_index % total_sources]\n",
    "    source_index += 1\n",
    "    \n",
    "    orig_filename = str(row['filename']).strip()\n",
    "    noise_class = str(row['category']).strip()\n",
    "    source_path = os.path.join(NOISE_SOURCE_FOLDER, orig_filename)\n",
    "    \n",
    "    if not os.path.exists(source_path): continue\n",
    "\n",
    "    # Determine: Copy (Round 1) or Augment (Round 2+)?\n",
    "    is_augmentation = (source_index > total_sources)\n",
    "    \n",
    "    # Destination Setup\n",
    "    location = \"GeneralForest\"\n",
    "    label = \"NoEagleSound\"\n",
    "    save_folder = os.path.join(EXISTING_OUTPUT_FOLDER, location, label)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        if not is_augmentation:\n",
    "            # --- METHOD A: DIRECT COPY (Fast) ---\n",
    "            new_filename = f\"GeneralForest_{noise_class}_{orig_filename}\"\n",
    "            dest_path = os.path.join(save_folder, new_filename)\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "            \n",
    "        else:\n",
    "            # --- METHOD B: AUGMENTATION (Fill the rest) ---\n",
    "            # Load\n",
    "            y, sr = librosa.load(source_path, sr=None)\n",
    "            \n",
    "            # Augment: Pitch Shift (Randomly slightly higher or lower)\n",
    "            steps = np.random.uniform(-1.5, 1.5)\n",
    "            y_aug = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)\n",
    "            \n",
    "            # Save as new file\n",
    "            new_filename = f\"GeneralForest_{noise_class}_aug{source_index}_{orig_filename}\"\n",
    "            dest_path = os.path.join(save_folder, new_filename)\n",
    "            sf.write(dest_path, y_aug, sr)\n",
    "\n",
    "        # Add to Manifest Data\n",
    "        new_row = {col: '' for col in manifest_columns} # Init empty\n",
    "        new_row.update({\n",
    "            'label': label,\n",
    "            'label_base': label,\n",
    "            'label_full': label,\n",
    "            'group_id': next_group_id + created_count,\n",
    "            'location_id': location,\n",
    "            'segment_filename': new_filename,\n",
    "            'output_folder': os.path.join(location, label),\n",
    "            'source_audio': orig_filename,\n",
    "            'start': 0.0,\n",
    "            'end': 5.0,\n",
    "            'quality': 'N/A',\n",
    "            'selection_numbers': 'None'\n",
    "        })\n",
    "        \n",
    "        segments_data.append(new_row)\n",
    "        created_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        pass\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n‚ú® DONE! Created {created_count} files ({len(filtered_df)} originals + {created_count - len(filtered_df)} augmented).\")\n",
    "\n",
    "# ===============================\n",
    "# SAVE MANIFEST\n",
    "# ===============================\n",
    "if segments_data:\n",
    "    print(\"Updating manifest...\")\n",
    "    new_df = pd.DataFrame(segments_data)\n",
    "    new_df = new_df[manifest_columns] # Align columns\n",
    "    combined = pd.concat([existing_manifest, new_df], ignore_index=True)\n",
    "    combined.to_csv(manifest_path, index=False)\n",
    "    print(\"‚úÖ Manifest updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56a286",
   "metadata": {},
   "source": [
    "## **DEFICIT FILLER USING XENO CANTO DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab6e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ü¶Ö PROCESSING KAGGLE BIRD DATASET (DEFICIT FILLER)\n",
      "======================================================================\n",
      "\n",
      "üìä Current Status:\n",
      "   ‚Ä¢ Current NoEagle: 4458\n",
      "   ‚Ä¢ Target Count:    14890\n",
      "   ‚Ä¢ Files Needed:    10432\n",
      "   ‚Ä¢ Starting group_id: 5167\n",
      "\n",
      "üìã Loading metadata...\n",
      "   ‚Ä¢ Total candidate files: 23784\n",
      "   ‚Ä¢ Priority raptors: 505\n",
      "\n",
      "üîç Indexing audio files in subfolders...\n",
      "   ‚úÖ Indexed 14685 audio files.\n",
      "\n",
      "üéµ Processing audio files (resampling to 16000Hz)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating segments:   0%|          | 0/10432 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è No files added. Check paths.\n",
      "   Skipped 23784 files (missing or too short)\n",
      "\n",
      "======================================================================\n",
      "üéâ Processing Complete!\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "# ===============================\n",
    "# USER SETTINGS\n",
    "# ===============================\n",
    "# 1. Audio Source (Point to the folder containing 'A-M' or subfolders)\n",
    "# Based on your diagnostic: D:/.../archive3/A-M\n",
    "NOISE_SOURCE_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive3/A-M\"\n",
    "\n",
    "# 2. Metadata CSV\n",
    "METADATA_PATH = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive3/train_extended.csv\"\n",
    "\n",
    "# 3. Output\n",
    "EXISTING_OUTPUT_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/3_SegmentedAudios\"\n",
    "MANIFEST_PATH = os.path.join(EXISTING_OUTPUT_FOLDER, \"master_manifest_NoEagle.csv\")\n",
    "\n",
    "# 4. Target\n",
    "TARGET_DEFICIT = 14890\n",
    "SEGMENT_LENGTH = 5.0\n",
    "TARGET_SR = 16000  # YAMNet Standard\n",
    "\n",
    "# 5. Priority List (Hard Negatives)\n",
    "PRIORITY_SPECIES = [\n",
    "    \"Bald Eagle\", \"Red-tailed Hawk\", \"Broad-winged Hawk\", \n",
    "    \"Cooper's Hawk\", \"Sharp-shinned Hawk\", \"Osprey\", \n",
    "    \"Peregrine Falcon\", \"Merlin\", \"American Kestrel\", \n",
    "    \"Northern Harrier\", \"Red-shouldered Hawk\", \"Swainson's Hawk\",\n",
    "    \"Barred Owl\", \"Great Horned Owl\"\n",
    "]\n",
    "\n",
    "# 6. Safety Exclusions\n",
    "EXCLUDED_SCIENTIFIC = [\"Pithecophaga jefferyi\"]\n",
    "EXCLUDED_COMMON = [\"Philippine Eagle\"]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ü¶Ö PROCESSING KAGGLE BIRD DATASET (DEFICIT FILLER)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ===============================\n",
    "# STEP 1: CALCULATE NEED\n",
    "# ===============================\n",
    "if not os.path.exists(MANIFEST_PATH):\n",
    "    print(\"‚ùå No existing manifest found. Please create master_manifest_NoEagle.csv first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "existing_manifest = pd.read_csv(MANIFEST_PATH, encoding='utf-8-sig')\n",
    "existing_manifest.columns = [c.strip() for c in existing_manifest.columns]\n",
    "manifest_columns = existing_manifest.columns.tolist()\n",
    "current_count = len(existing_manifest)\n",
    "files_needed = TARGET_DEFICIT - current_count\n",
    "\n",
    "print(f\"\\nüìä Current Status:\")\n",
    "print(f\"   ‚Ä¢ Current NoEagle: {current_count}\")\n",
    "print(f\"   ‚Ä¢ Target Count:    {TARGET_DEFICIT}\")\n",
    "print(f\"   ‚Ä¢ Files Needed:    {files_needed}\")\n",
    "\n",
    "if files_needed <= 0:\n",
    "    print(\"\\n‚úÖ Deficit already filled!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Get next group ID\n",
    "if 'group_id' in existing_manifest.columns:\n",
    "    try:\n",
    "        next_group_id = int(existing_manifest['group_id'].max()) + 1\n",
    "    except:\n",
    "        next_group_id = 60000\n",
    "else:\n",
    "    next_group_id = 60000\n",
    "\n",
    "print(f\"   ‚Ä¢ Starting group_id: {next_group_id}\")\n",
    "\n",
    "# ===============================\n",
    "# STEP 2: LOAD & VALIDATE METADATA\n",
    "# ===============================\n",
    "print(\"\\nüìã Loading metadata...\")\n",
    "\n",
    "if not os.path.exists(METADATA_PATH):\n",
    "    print(f\"‚ùå Metadata file not found: {METADATA_PATH}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    meta_df = pd.read_csv(METADATA_PATH, encoding='utf-8-sig')\n",
    "    meta_df.columns = [c.strip() for c in meta_df.columns]\n",
    "    \n",
    "    # Detect column names\n",
    "    col_common = None\n",
    "    col_sci = None\n",
    "    col_file = None\n",
    "    \n",
    "    for col in meta_df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'common' in col_lower and 'name' in col_lower: col_common = col\n",
    "        elif 'scientific' in col_lower or 'species' in col_lower: col_sci = col\n",
    "        elif 'filename' in col_lower or 'file' in col_lower: col_file = col\n",
    "    \n",
    "    if not col_file:\n",
    "        print(f\"‚ùå Could not find filename column in metadata.\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if not col_common: col_common = 'species' \n",
    "    \n",
    "    # Exclude Philippine Eagle\n",
    "    if col_sci and col_sci in meta_df.columns:\n",
    "        meta_df = meta_df[~meta_df[col_sci].isin(EXCLUDED_SCIENTIFIC)].copy()\n",
    "    \n",
    "    if col_common in meta_df.columns:\n",
    "        meta_df = meta_df[\n",
    "            ~meta_df[col_common].astype(str).str.lower().str.contains('philippine eagle', na=False)\n",
    "        ].copy()\n",
    "    \n",
    "    # Mark priority species\n",
    "    if col_common in meta_df.columns:\n",
    "        meta_df['is_priority'] = meta_df[col_common].apply(\n",
    "            lambda x: any(p.lower() in str(x).lower() for p in PRIORITY_SPECIES)\n",
    "        )\n",
    "    else:\n",
    "        meta_df['is_priority'] = False\n",
    "    \n",
    "    # Sort: priority first\n",
    "    meta_df = meta_df.sort_values(by=['is_priority'], ascending=False)\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Total candidate files: {len(meta_df)}\")\n",
    "    print(f\"   ‚Ä¢ Priority raptors: {meta_df['is_priority'].sum()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading metadata: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ===============================\n",
    "# STEP 3: INDEX AUDIO FILES\n",
    "# ===============================\n",
    "print(f\"\\nüîç Indexing audio files in subfolders...\")\n",
    "file_map = {}\n",
    "for root, dirs, files in os.walk(NOISE_SOURCE_FOLDER):\n",
    "    for f in files:\n",
    "        if f.endswith('.mp3') or f.endswith('.wav') or f.endswith('.ogg'):\n",
    "            file_map[f] = os.path.join(root, f)\n",
    "\n",
    "print(f\"   ‚úÖ Indexed {len(file_map)} audio files.\")\n",
    "\n",
    "# ===============================\n",
    "# STEP 4: PROCESS AUDIO\n",
    "# ===============================\n",
    "segments_data = []\n",
    "created_count = 0\n",
    "error_count = 0\n",
    "skipped_count = 0\n",
    "\n",
    "print(f\"\\nüéµ Processing audio files (resampling to {TARGET_SR}Hz)...\")\n",
    "pbar = tqdm(total=files_needed, desc=\"Creating segments\")\n",
    "\n",
    "for index, row in meta_df.iterrows():\n",
    "    if created_count >= files_needed:\n",
    "        break\n",
    "    \n",
    "    filename_csv = str(row[col_file]).strip()\n",
    "    \n",
    "    # Handle extensions\n",
    "    candidates = [filename_csv]\n",
    "    if not (filename_csv.endswith('.mp3') or filename_csv.endswith('.wav')):\n",
    "        candidates = [filename_csv + '.mp3', filename_csv + '.wav']\n",
    "        \n",
    "    # Find file\n",
    "    source_path = None\n",
    "    real_filename = None\n",
    "    \n",
    "    for cand in candidates:\n",
    "        if cand in file_map:\n",
    "            source_path = file_map[cand]\n",
    "            real_filename = cand\n",
    "            break\n",
    "            \n",
    "    if not source_path:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "    \n",
    "    common_name = str(row.get(col_common, 'Unknown'))\n",
    "    is_raptor = row.get('is_priority', False)\n",
    "    \n",
    "    try:\n",
    "        # Load & Resample\n",
    "        y, sr = librosa.load(source_path, sr=TARGET_SR, mono=True)\n",
    "        duration = len(y) / sr\n",
    "        num_chunks = int(duration // SEGMENT_LENGTH)\n",
    "        \n",
    "        if num_chunks < 1:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        for i in range(num_chunks):\n",
    "            if created_count >= files_needed: break\n",
    "            \n",
    "            start_sample = int(i * SEGMENT_LENGTH * sr)\n",
    "            end_sample = int((i + 1) * SEGMENT_LENGTH * sr)\n",
    "            \n",
    "            if end_sample > len(y): break\n",
    "            \n",
    "            chunk = y[start_sample:end_sample]\n",
    "            \n",
    "            loc_id = \"ConfusingRaptors\" if is_raptor else \"GeneralBirds\"\n",
    "            label = \"NoEagleSound\"\n",
    "            \n",
    "            save_folder = os.path.join(EXISTING_OUTPUT_FOLDER, loc_id, label)\n",
    "            os.makedirs(save_folder, exist_ok=True)\n",
    "            \n",
    "            safe_common = \"\".join([c for c in common_name if c.isalnum() or c in (' ', '_')]).strip().replace(' ', '_')\n",
    "            safe_fname = os.path.splitext(real_filename)[0]\n",
    "            new_filename = f\"Kaggle_{safe_common}_{safe_fname}_seg{i:02d}.wav\"\n",
    "            \n",
    "            save_path = os.path.join(save_folder, new_filename)\n",
    "            sf.write(save_path, chunk, TARGET_SR)\n",
    "            \n",
    "            # Add to Data\n",
    "            new_row = {col: '' for col in manifest_columns}\n",
    "            new_row.update({\n",
    "                'label': label,\n",
    "                'label_base': label,  # <--- HERE IS THE FIX\n",
    "                'label_full': label,\n",
    "                'location_id': loc_id, \n",
    "                'segment_filename': new_filename,\n",
    "                'output_folder': os.path.join(loc_id, label),\n",
    "                'source_audio': real_filename,\n",
    "                'start': 0.0, \n",
    "                'end': SEGMENT_LENGTH,\n",
    "                'segment_start_time': 0.0, \n",
    "                'segment_end_time': SEGMENT_LENGTH,\n",
    "                'segment_duration': SEGMENT_LENGTH,\n",
    "                'group_id': next_group_id,\n",
    "                'quality': 'High',\n",
    "                'label_category': 'NoEagleSound'\n",
    "            })\n",
    "            \n",
    "            segments_data.append(new_row)\n",
    "            created_count += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "        next_group_id += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_count += 1\n",
    "        continue\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# ===============================\n",
    "# STEP 5: SAVE MANIFEST\n",
    "# ===============================\n",
    "if segments_data:\n",
    "    print(f\"\\nüíæ Saving Manifest...\")\n",
    "    new_df = pd.DataFrame(segments_data)\n",
    "    new_df = new_df[manifest_columns]\n",
    "    \n",
    "    combined = pd.concat([existing_manifest, new_df], ignore_index=True)\n",
    "    combined.to_csv(MANIFEST_PATH, index=False)\n",
    "    \n",
    "    raptors = sum(1 for s in segments_data if 'ConfusingRaptors' in s['location_id'])\n",
    "    general_count = len(new_df) - raptors\n",
    "    \n",
    "    print(f\"‚úÖ SUCCESS!\")\n",
    "    print(f\"   ‚Ä¢ Added: {len(new_df)} files\")\n",
    "    print(f\"   ‚Ä¢ Raptors: {raptors}\")\n",
    "    print(f\"   ‚Ä¢ General Birds: {general_count}\")\n",
    "    print(f\"   ‚Ä¢ Total in Manifest: {len(combined)}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No files added. Check paths.\")\n",
    "    print(f\"   Skipped {skipped_count} files (missing or too short)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ Processing Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cda6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DIAGNOSTIC START ---\n",
      "‚úÖ Folder exists: D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive3/A-M\n",
      "   Found 14685 audio files.\n",
      "   Sample path: D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive3/A-M\\aldfly\\XC133197.mp3\n",
      "\n",
      "‚úÖ CSV exists: D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive3/train_extended.csv\n",
      "   Columns: ['rating', 'playback_used', 'ebird_code', 'channels', 'date', 'duration', 'filename', 'species', 'title', 'secondary_labels', 'bird_seen', 'sci_name', 'location', 'latitude', 'sampling_rate', 'type', 'elevation', 'bitrate_of_mp3', 'file_type', 'background', 'xc_id', 'url', 'country', 'author', 'primary_label', 'longitude', 'time', 'recordist', 'license']\n",
      "   Rows: 23784\n",
      "   Found 61 rows matching 'Bald Eagle' or 'Red-tailed Hawk'\n",
      "--- DIAGNOSTIC END ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================\n",
    "# DIAGNOSTIC TOOL\n",
    "# ===============================\n",
    "NOISE_SOURCE_FOLDER = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/birds_songs/songs\"\n",
    "METADATA_PATH = r\"D:/_3rd Year Class/1st Sem/Machine Learning/_ForLE/For DataSet/archive3/train_extended.csv\"\n",
    "\n",
    "print(\"--- DIAGNOSTIC START ---\")\n",
    "\n",
    "# 1. Check Folder\n",
    "if os.path.exists(NOISE_SOURCE_FOLDER):\n",
    "    print(f\"‚úÖ Folder exists: {NOISE_SOURCE_FOLDER}\")\n",
    "    # Count files\n",
    "    file_count = 0\n",
    "    sample_files = []\n",
    "    for root, dirs, files in os.walk(NOISE_SOURCE_FOLDER):\n",
    "        for f in files:\n",
    "            if f.endswith(('.mp3', '.wav')):\n",
    "                file_count += 1\n",
    "                if len(sample_files) < 5: sample_files.append(os.path.join(root, f))\n",
    "    \n",
    "    print(f\"   Found {file_count} audio files.\")\n",
    "    if file_count > 0:\n",
    "        print(f\"   Sample path: {sample_files[0]}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå FOLDER IS EMPTY or contains no mp3/wav!\")\n",
    "else:\n",
    "    print(f\"‚ùå Folder NOT found: {NOISE_SOURCE_FOLDER}\")\n",
    "\n",
    "# 2. Check CSV\n",
    "if os.path.exists(METADATA_PATH):\n",
    "    print(f\"\\n‚úÖ CSV exists: {METADATA_PATH}\")\n",
    "    try:\n",
    "        df = pd.read_csv(METADATA_PATH)\n",
    "        print(f\"   Columns: {list(df.columns)}\")\n",
    "        print(f\"   Rows: {len(df)}\")\n",
    "        \n",
    "        # Check Priority Species match\n",
    "        PRIORITY = [\"Bald Eagle\", \"Red-tailed Hawk\"]\n",
    "        mask = df.apply(lambda row: row.astype(str).str.contains('|'.join(PRIORITY), case=False).any(), axis=1)\n",
    "        print(f\"   Found {mask.sum()} rows matching 'Bald Eagle' or 'Red-tailed Hawk'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå CSV Read Error: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå CSV NOT found: {METADATA_PATH}\")\n",
    "\n",
    "print(\"--- DIAGNOSTIC END ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
